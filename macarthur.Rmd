---
title: "MacArthur Data"
author:
- name: "Kieran Healy"
  affiliation: "Duke University"
  email: "kjhealy@soc.duke.edu"
date: "9/27/2019"
output:
  pdf_document:
    template: ~/.pandoc/templates/rmd-latex.template
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.showtext=TRUE)
```

```{r libraries, echo = FALSE}
library(tidyverse)
library(rvest)
library(socviz)
library(ggrepel)
```

```{r theme, echo = FALSE}
library(showtext)
showtext_auto()
library(myriad)
import_myriad_semi()

theme_set(theme_myriad_semi())
```

# Initial data scraping and saving to local storage

## Scrape the Website

Get a List of all MacArthur Fellows from `macfound.org` and put them in a list. Don't do this more than once! This code is not evaluated when knitting the document, because we only have to do it once.

```{r, eval = FALSE, echo = TRUE}

## Generate vector of fellow page urls
urls <- paste0("https://www.macfound.org/fellows/", 1:1054, "/")


## Grab the full Macfound page of every awardee from macfound.org
bio_pages <- urls %>% 
  map(~ {
    message(glue::glue("* parsing: {.x}"))
    Sys.sleep(5) # try to be polite
    safely(read_html)(.x)
  })

```

## Save the scraped webpages locally

There's a gotcha with objects like `bio_pages`: they cannot be straightforwardly saved to R's native data format with `save()`. The XML files are stored with external pointers to their content and cannot be "serialized" in a way that saves their content properly. If you try, when you `load()` the saved object you will get complaints about missing pointers. So instead, we'll unspool our list and  save each fellow's page individually. Then if we want to rerun this analysis without crawling everything again, we will load them in from our local saved versions using `read_html()`.

Again, this code chunk is shown but not run, as we only do it once. 

```{r localsave, eval = FALSE, echo = TRUE}

## Get a list containing every fellow's webpage, 
## Drop the safely() error codes from the initial scrape, and 
## and also drop any NULL entries
page_list <- pluck(bio_pages, "result") %>% 
  compact()

## Make a vector of clean file names of the form "raw/macfound.org/jane_doe.html"
## One for every fellow. Same order as the page_list.
fnames <-paste0("raw/macfound.org/", 
                janitor::make_clean_names(fellows$name),
                ".html") 
names(fnames) <- fellows$name   

## Walk the elements of the page list and the file names to 
## save each HTML file under is respective clean file name
walk2(page_list, fnames, ~ write_xml(.x, file = .y))

```

# Parse the pages 

Using the local data we've saved, we read in a list of all the MacArthur Fellow web pages.

```{r localparse}

## The filenames we just created
local_urls <- fs::dir_ls("raw/macfound.org/")

## Grab the full Macfound page of every awardee. 
bio_pages <- local_urls %>% 
  map(~ {
    safely(read_html)(.x)
  })

## summary first ten
summary(bio_pages)[1:5,]

## E.g. first record
bio_pages[[1]]

```

Next, we parse every webpage to create a record for each fellow. Here's the function that will do the work:

```{r}
get_fellow <- function(x) {
    ifelse(is.null(x), return(NA), FALSE)
    
    f_name <- rvest::html_node(x, ".has-top-margin") %>%
          rvest::html_text(trim = TRUE)

    year_string <- "Class of( January| February| March| April| May| June| July| August| September| October| November| December)?\\s+\\d{4}"        
    f_year <- rvest::html_node(x, "h2") %>%
          rvest::html_text(trim = TRUE) %>%
          stringr::str_extract(year_string) %>%
          stringr::str_extract("\\d{4}")
  
    out <- rvest::html_node(x, ".photo-bio__content") %>%
          rvest::html_text(trim = TRUE) %>%
          stringr::str_remove_all("\n              ")
        
    f_title <- str_trim(str_match(out, "Title (.*?) Affiliation")[,2])
    f_affil <- str_trim(str_match(out, "Affiliation (.*?) Location")[,2])
    f_loc <- str_trim(str_match(out, "Location (.*?) Age")[,2])
    f_age <- str_trim(str_extract(out, "Age(.*?)\\d{2}")) %>% 
      str_extract("\\d{2}")
    f_area <- str_trim(str_match(out, "Area of Focus (.*?)$")[,2])

    f_bio <- rvest::html_node(x, ":nth-child(3) .text-content--small") %>%
            rvest::html_text()     
    
    record <- tibble(
      name = f_name,
      year = f_year,
      title = f_title,
      affiliation = f_affil,
      location = f_loc,
      age = f_age,
      area = f_area,
      bio = f_bio)
    
    record
  }

```

Now we apply it to the list of pages:

```{r}

fellows <-  bio_pages %>% 
  pluck("result") %>% # Get the webpages
  compact() %>% # Drop any empties
  map(get_fellow) %>% # Generate the individual records
  bind_rows() # and combine

fellows

```

# Cleaning the data

We write a function to guess the gender of the fellow from their bio information. 

```{r}

infer_gender <- function(bio){
  m_test <- str_detect(bio, "(\\b[Hh]e is)|(\\b[Hh]e was)|\\b[H]is\\b|\\b([Hh]e joined)|(\\b[Hh]e has)|\\b[Hh]e explore|\\b[Hh]e also|\\b[Hh]e produced|\\b[Hh]e founded|\\b[Hh]e worked|\\b[Hh]is work|\\b[Hh]is research")
  f_test <- str_detect(bio, "(\\b[Ss]he is)|(\\b[Ss]he was)|\\b[H]er\\b|\\b([Ss]he joined)|(\\b[Ss]he has)|\\b[Ss]he explore|\\b[Ss]he also|\\b[Ss]he produced|\\b[Ss]he founded|\\b[Ss]he worked|\\b[Hh]er work|\\b[Hh]er research")
  
  out <- case_when(
    m_test == TRUE & f_test == FALSE ~ "Male", 
    m_test == FALSE & f_test == TRUE ~ "Female",
    TRUE ~ NA_character_
    )
  out
}
```

We apply it to our data, also making the (character) records of age and fellowship year into integers and dates, respectively:

```{r}
fellows <- fellows %>%
  mutate(age = as.integer(age),
         year = int_to_year(as.integer(year)),
         sex = infer_gender(bio)) %>%
  select(name, year, age, sex, title, everything())

fellows
```

## Manually recoding records 

```{r}
## Eiko and Koma Otake
koma <- fellows %>% filter(name == "Eiko and Koma Otake")
koma$name <- "Koma Otake"

eiko <- fellows %>% filter(name == "Eiko and Koma Otake")
eiko$name <- "Eiko Otake"

fellows <- fellows %>% filter(name %nin% "Eiko and Koma Otake")
fellows <- rbind(fellows, eiko, koma)

## Manually code the remaining gender vals
fellows %>% filter(is.na(sex)) %>% select(name) %>% data.frame()

fellows <- fellows %>%
  mutate(sex = case_when(
  name == "Lin He" ~ as.character("Female"),
  name == "Aaron Shirley" ~ as.character("Male"),
  name == "Michael Lerner" ~ as.character("Male"),
  name == "Edward V. Roberts" ~ as.character("Male"),
  name == "Aaron Lansky" ~ as.character("Male"),
  name == "Patricia Locke" ~ as.character("Female"),
  name == "Robert H. McCabe" ~ as.character("Male"),
  name == "Jeraldyne Blunden" ~ as.character("Female"),
  name == "Martin Daniel Eakes" ~ as.character("Male"),
  name == "Louis Massiah" ~ as.character("Male"),
  name == "Eiko Otake" ~ as.character("Female"),
  name == "Koma Otake" ~ as.character("Male"),
  name == "Kun-Liang Guan" ~ as.character("Male"),
  name == "William W. McDonald" ~ as.character("Male"),
  name == "Juan Martin Maldacena" ~ as.character("Male"),
  name == "Ken Vandermark" ~ as.character("Male"),
  name == "Lucy Blake" ~ as.character("Female"),
  name == "Katherine Gottlieb" ~ as.character("Female"),
  name == "Nancy Siraisi" ~ as.character("Female"),
  name == "Whitfield Lovell" ~ as.character("Male"),
  name == "Junot DÃ­az" ~ as.character("Male"),
  name == "Jeffrey Brenner" ~ as.character("Male"),
  name == "Michelle Dorrance" ~ as.character("Female"),
  name == "Nicole Eisenman" ~ as.character("Female"),
  name == "LaToya Ruby Frazier" ~ as.character("Female"),
  name == "Taylor Mac" ~ as.character("Male"),
  #name == "Wu Tsang" ~ as.character(), ## one nonbinary case
  name == "Cameron Rowland" ~ as.character("Male"),
  TRUE ~ sex))

```

## Clean the `area` field a little

```{r}

clean_area <- function(x) {
  stringr::str_remove(x, "(Website|Twitter).*$") %>%
  stringr::str_squish()
}

fellows <- fellows %>%
  mutate(area = clean_area(area))

```

## Clean Affiliation and Title

```{r}
fellows <- fellows %>%
  mutate(affiliation = replace_na(affiliation, "None Provided"), 
         title = replace_na(title, "None Provided"),
         area = replace_na(area, "None Provided"),
         affil_short = str_trim(str_remove_all(affiliation, "(School of.*?,)|(College of.*?,)|(Division of.*?,)|(Department of.*?,)|(, .*?Department)|(Center.*?,)")), 
         title_short = str_trim(str_remove_all(title, ",.*$")),
         area_short = str_trim(str_remove_all(area, ",.*$")))

fellows

```


## Write out the cleaned data to a CSV file

```{r}
write_csv(fellows, "data/macarthur-mfd.csv")

## Partital selection for class problem set:
## fellows %>% select(name, year, age, sex) %>%
## write_csv("~/Documents/courses/visualizingsociety.com/static/data/macarthur.csv")

```




# Make some plots
  
```{r, fig.width = 12}

p <- ggplot(data = fellows, 
              mapping = aes(x = year, y = age, group = year))

p + geom_jitter(alpha = 0.5, shape = 1, position = position_jitter()) +  
  geom_boxplot(outlier.size = 0, 
                   fill = my.colors("bly")[2], 
                   alpha = 0.2) + 
  theme(legend.position = "top") +
  labs(x = "Year of Award", y = "Age at Time of Award", 
       title = "Age Distribution of MacArthur Award Winners 1981-2019", 
       caption = "Kieran Healy @kjhealy socviz.co / Data: MacArthur Foundation.") + 
  scale_x_date(breaks = c(int_to_year(1981), 
                          int_to_year(1991), 
                          int_to_year(2001), 
                          int_to_year(2011), 
                          int_to_year(2019)), 
               labels = c("1981", "1991", "2001", "2011", "2019")) + 
  theme(axis.text = element_text(size = rel(1.25)),
        axis.title = element_text(size = rel(1.25)), 
        plot.title = element_text(size = rel(1.75)),
        plot.caption = element_text(size = rel(1.1)))
```

```{r, fig.width = 12}

p <-   ggplot(data = subset(fellows, !is.na(sex)), 
              mapping = aes(x = year, y = age, 
                       color = sex,
                       fill = sex)) 
p + geom_jitter(alpha = 0.8, shape = 1, position = position_jitter(height = 0.2)) + 
  geom_smooth() +
  theme(legend.position = "top") +
  labs(x = "Year of Award", y = "Age at Time of Award", 
       title = "Age Distribution of MacArthur Winners over time")
```
```{r, fig.width = 12}
fellows %>%
  group_by(sex) %>%
  tally() %>%
 mutate(pct = (n / sum(n))*100)

p <- ggplot(data = subset(fellows, !is.na(sex)), 
              mapping = aes(x = year, y = age, color = sex, fill = sex)) 
p + geom_boxplot(outlier.colour = NA, 
                   mapping = aes(group = interaction(year, sex), 
                                 color = sex,
                                 fill = sex), alpha = 0.3) + 
  geom_jitter(alpha = 0.4, shape = 1, 
              position = position_jitter(height = 0.2)) + 
  theme(legend.position = "top") +
  scale_fill_manual(values = my.colors("bly")) + 
  scale_color_manual(values = my.colors("bly")) +
  labs(x = "Year of Award", y = "Age at Time of Award", 
       color = "Gender", fill = "Gender",
       title = "Age Distribution of MacArthur Winners over time")


```

# Make some tables

```{r}

fellows %>% 
  group_by(affil_short) %>%
  tally() %>%
  mutate(freq = n / sum(n),
         pct = round((freq*100), 1)) %>%
  arrange(desc(pct)) %>% 
  filter(n > 2) %>%
  select(affil_short, n, pct)


fellows %>% 
  group_by(title_short) %>%
  tally() %>%
  mutate(freq = n / sum(n),
         pct = round((freq*100), 1)) %>%
  arrange(desc(pct)) %>% 
  filter(n > 2) %>%
  select(title_short, n, pct)
```

```{r, fig.height=12, fig.width=10}
fellows %>% 
  group_by(area_short) %>%
  tally() %>%
  mutate(freq = n / sum(n),
         pct = round((freq*100), 1), 
         n_lab = paste0(area_short," (", n, ")")) %>%
  arrange(desc(pct)) %>% 
  filter(pct >=1) %>%
  select(n_lab, n, pct) %>%
  ggplot(mapping = aes(x = pct, y = reorder(n_lab, pct))) + 
  geom_point(size = 3) + 
  labs(x = "Percent of All Awards", 
       y = NULL, 
       title = "MacArthur Fellowships by Area, 1981-2019", 
       subtitle = "Areas with one percent or more of all awards",
      caption = "Kieran Healy @kjhealy socviz.co / Data: MacArthur Foundation.") +
  theme(axis.text = element_text(size = rel(1.25)),
        axis.title = element_text(size = rel(1.25)), 
        plot.title = element_text(size = rel(1.75)),
        plot.caption = element_text(size = rel(1.1)))  
```

```{r}

fellows %>% 
  group_by(location) %>%
  tally() %>%
  mutate(freq = n / sum(n),
         pct = round((freq*100), 1)) %>%
  arrange(desc(pct)) %>% 
  filter(pct >= 1) %>%
  select(location, n, pct)



```

# Session Information

```{r}
sessioninfo::session_info()
```

